{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAeG440fB7y3"
      },
      "source": [
        "## Exemplo de segmentação utilizando Detectron2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_767SpEGD2zJ"
      },
      "source": [
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "O [dataset](https://universe.roboflow.com/nutritionverse/mealsynth) utilizado neste exemplo é constituído por 913 imagens (49 classes) de diferentes alimentos.\n",
        "\n",
        "Treino: 624\n",
        "\n",
        "Validação: 265\n",
        "\n",
        "Teste: 24\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5DwluqC5ID2"
      },
      "source": [
        "## Aceder ao Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5e5MipFBy7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/') # nome da pasta onde serão colocados os ficheiros do Google Drive -> /nome_da_pasta/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MJ8SshpLaU3"
      },
      "source": [
        "## Instalar Detectron2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM1JmUCQLdKp"
      },
      "outputs": [],
      "source": [
        "# instalar repositório através do Git\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4YkO2GNiavL"
      },
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEKfPKFmW54"
      },
      "outputs": [],
      "source": [
        "# Geral\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Preparação do dataset\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# Visualização\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# Configuração\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# Avaliação\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# Treino\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXjaGHnbDcyL"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "Fazer unzip do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykh6PZopDcIi"
      },
      "outputs": [],
      "source": [
        "# Unzip do dataset\n",
        "!unzip /content/drive/MyDrive/Exemplo_Codigo/datasets/comida.zip -d /content/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoB31yi4AoYs"
      },
      "source": [
        "# Localização do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbI2PNEZF3sU"
      },
      "outputs": [],
      "source": [
        "DATA_SET_NAME = \"comida\" # nome do dataset\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\" # anotações\n",
        "data_location = \"/content/data/comida/\" # caminho do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jntOI8GJG2ks"
      },
      "outputs": [],
      "source": [
        "# Dados de treino\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(data_location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(data_location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# Dados de teste\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(data_location, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(data_location, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TEST_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# Dados de validação\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(data_location, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(data_location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name = VALID_DATA_SET_NAME,\n",
        "    metadata = {},\n",
        "    json_file = VALID_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root = VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDpU2L3UL922"
      },
      "source": [
        "# Visualizar dados de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE0anblvMGJx"
      },
      "outputs": [],
      "source": [
        "# Exemplo de dados de treino\n",
        "\n",
        "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
        "\n",
        "dataset_entry = dataset_train[0]\n",
        "image = cv2.imread(dataset_entry[\"file_name\"])\n",
        "\n",
        "visualizer = Visualizer(\n",
        "    image[:, :, : : -1],\n",
        "    metadata = metadata,\n",
        "    scale = 0.8,\n",
        "    instance_mode = ColorMode.IMAGE_BW\n",
        ")\n",
        "\n",
        "out = visualizer.draw_dataset_dict(dataset_entry)\n",
        "cv2_imshow(out.get_image()[:, :, : : -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavGRHy2M7Hb"
      },
      "source": [
        "# Treinar modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ3g-l56NMOY"
      },
      "source": [
        "## Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krCm2L_lNC83"
      },
      "outputs": [],
      "source": [
        "# Parâmetros\n",
        "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\" # arquitetura utilizada no treino\n",
        "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\" # configuração do modelo\n",
        "MAX_ITER = 1000 # número de iterações\n",
        "EVAL_PERIOD = 200 # patience\n",
        "BASE_LR = 0.001 # learning rate\n",
        "NUM_CLASSES = 49 # número de classes\n",
        "\n",
        "# Output\n",
        "OUTPUT_DIR_PATH = os.path.join(\n",
        "    DATA_SET_NAME,\n",
        "    ARCHITECTURE,\n",
        "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        ")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxQU8JrgOD73"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH) # pesos\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,) # dados de treino\n",
        "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,) # dados de teste\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32 # feature maps por cada imagem\n",
        "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD # gravar os resultados a cada x iterações\n",
        "cfg.DATALOADER.NUM_WORKERS = 2 # número de workers a trabalhar -> carregar os dados\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2 # batch utilizada em cada iteração\n",
        "cfg.INPUT.MASK_FORMAT='bitmask' # apenas a máscara se encontra a cores\n",
        "cfg.SOLVER.BASE_LR = BASE_LR\n",
        "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH # caminho dos outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-_5aCuXWj9"
      },
      "source": [
        "## Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S8y2W2AQvJq"
      },
      "outputs": [],
      "source": [
        "trainer = DefaultTrainer(cfg) # modelo de treino\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train() # treino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flInE1L-XTfx"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsByFDFbQwLi"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") # pesos\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # confiança mínima de cada feature map\n",
        "predictor = DefaultPredictor(cfg) # modelo de previsões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hmAcBbpXX-Rh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# inferências\n",
        "\n",
        "# utilizar imagens de teste\n",
        "img = cv2.imread(\"\")\n",
        "outputs = predictor(img)\n",
        "\n",
        "visualizer = Visualizer(\n",
        "    img[:, :, ::-1],\n",
        "    metadata=metadata,\n",
        "    scale=0.8,\n",
        "    instance_mode=ColorMode.IMAGE_BW\n",
        ")\n",
        "out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYGk-zJz4mQF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}