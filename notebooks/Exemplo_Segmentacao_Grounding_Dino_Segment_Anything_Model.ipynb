{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8dFvAbMLzxG"
      },
      "source": [
        "# Exemplo de Segmentação utilizando Grounding Dino e Segment Anything Model\n",
        "\n",
        "[Grounding Dino](https://github.com/IDEA-Research/GroundingDINO) -> efetua deteções de forma automática com base em prompts (palavras chave/frases)\n",
        "\n",
        "[Segment Anything Model](https://github.com/facebookresearch/segment-anything) -> efetua segmentações de forma automática, neste caso, com base em bounding boxes\n",
        "\n",
        "Efetuar o download de ambos os repositórios e colocar no Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vap0LeGtM5I-"
      },
      "source": [
        "## Instalar Grounding Dino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMwP3deaN5oj"
      },
      "outputs": [],
      "source": [
        "# clonar o repositório -> isto gera uma diretoria chamada \"GroundingDino\"\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "\n",
        "# entrar na diretoria\n",
        "%cd /content/GroundingDINO/\n",
        "\n",
        "# instalar dependências\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgdBCMd3O7TH"
      },
      "source": [
        "## Instalar Segment Anything Model (SAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q316WO3vOv7P"
      },
      "outputs": [],
      "source": [
        "# voltar à diretoria inicial\n",
        "%cd /content/\n",
        "\n",
        "# colar o repositório -> isto gera uma diretoria chamada \"segment-anything\"\n",
        "!git clone https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "# entrar na diretoria\n",
        "%cd /content/segment-anything/\n",
        "\n",
        "# instalar dependências\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r8tOX3yPgAu"
      },
      "source": [
        "## Efetuar download dos pesos do Grounding Dino\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0ZlRToePLd-"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "\n",
        "# criar uma nova diretoria\n",
        "!mkdir grounding_dino_weights\n",
        "\n",
        "# entrar na nova diretoria\n",
        "%cd grounding_dino_weights\n",
        "\n",
        "# efetuar o download dos pesos\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
        "\n",
        "# voltar à diretoria inicial\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yQF_Pu_kfEI"
      },
      "source": [
        "# **Importante**\n",
        "\n",
        "Depois de instalar os dois repositórios, fazer o seguinte:\n",
        "\n",
        "- Selecionar \"Tempo de execução\", que fica abaixo do título do notebook;\n",
        "- Selecionar \"Reiniciar sessão\";\n",
        "- Avançar para as próximas células."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5MKYV7xQEj-"
      },
      "source": [
        "## Bibliotecas do Grounding Dino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfleHBolP-_f"
      },
      "outputs": [],
      "source": [
        "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
        "from groundingdino.util import box_ops\n",
        "from PIL import Image # ler imagens\n",
        "\n",
        "from google.colab.patches import cv2_imshow # visualização de imagens\n",
        "\n",
        "import locale # evitar erros\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh23BGkrQPKu"
      },
      "source": [
        "## Utilização do modelo Grounding Dino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDe8YRmJj0YP"
      },
      "source": [
        "## **Carregar o modelo Grounding Dino**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjR3yKILj8xf"
      },
      "outputs": [],
      "source": [
        "# Carregar o modeo do Grounding Dino e os pesos\n",
        "modelo_gd = load_model(\"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\", \"/content/grounding_dino_weights/groundingdino_swint_ogc.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS9LTDR3j_v3"
      },
      "source": [
        "### **Parâmetros do Grounding Dino**\n",
        "\n",
        "O text prompt pode constituída por palavras ou frases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgHzReCQmtHY"
      },
      "outputs": [],
      "source": [
        "text_prompt = \"\" # prompt que vai ser utilizado para efetuar as deteções -> \".\" indica a procura dos diferentes objetos de forma individual\n",
        "box_threshold = 0.35 # número mínimo de similaridade entre as bounding boxes\n",
        "text_threshold = 0.25 # número mínimo de similaridade entre as bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCILutwpQQme"
      },
      "outputs": [],
      "source": [
        "img = \"/content/matricula.png\"\n",
        "\n",
        "# aplicação do modelo\n",
        "imagem_source, imagem = load_image(img)\n",
        "\n",
        "# a predição retorna todas as bounding boxes, logits (confiança) e a palavra/frase que deu origem à deteção\n",
        "boxes, logits, phrases = predict(\n",
        "    model = modelo_gd,\n",
        "    image = imagem,\n",
        "    caption = text_prompt,\n",
        "    box_threshold = box_threshold,\n",
        "    text_threshold = text_threshold\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1veqooeqQ_zu"
      },
      "source": [
        "## Resultados da deteção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYqNoOqUU_PX"
      },
      "source": [
        "### Imagem original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cXG1wtyVBLY"
      },
      "outputs": [],
      "source": [
        "Image.fromarray(imagem_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buWmk3cWVWOn"
      },
      "source": [
        "### Imagem com deteções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJaMDgpvRUSG"
      },
      "outputs": [],
      "source": [
        "annotated_frame = annotate(image_source = imagem_source, boxes = boxes, logits = logits, phrases = phrases)\n",
        "\n",
        "Image.fromarray(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijzHtmFPVoJX"
      },
      "source": [
        "## Utilização do SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z262jWgqV47v"
      },
      "source": [
        "## Bibliotecas do SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaRWtc1VV8XP"
      },
      "outputs": [],
      "source": [
        "# Geral\n",
        "import argparse\n",
        "import os\n",
        "import copy\n",
        "import supervision as sv\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torch\n",
        "from imutils import contours # para ordenar contornos\n",
        "\n",
        "# segment anything\n",
        "from segment_anything import build_sam, SamPredictor\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_DKAloKd53J"
      },
      "source": [
        "## Download do modelo SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmcig0CxXLku"
      },
      "outputs": [],
      "source": [
        "# carregar checkpoint do modelo SAM\n",
        "! wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AET-ltqXd9ZL"
      },
      "source": [
        "## Inicialização do modelo SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5kcxETlU3ZX"
      },
      "outputs": [],
      "source": [
        "sam_checkpoint = 'sam_vit_h_4b8939.pth' # pesos\n",
        "sam = build_sam(checkpoint = sam_checkpoint)\n",
        "sam.to(device = \"cuda\")\n",
        "sam_predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZG9GY1meAvQ"
      },
      "source": [
        "## Utilização do modelo SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_m0vI0fWYsI"
      },
      "outputs": [],
      "source": [
        "# Correr Segment Anything Model sobre a imagem\n",
        "sam_predictor.set_image(imagem_source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhE32awUbOAo"
      },
      "outputs": [],
      "source": [
        "# normalizar as bounding boxes obtidas pelo Grounding Dino\n",
        "H, W, _ = imagem_source.shape\n",
        "boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWCH0l3tbddo"
      },
      "outputs": [],
      "source": [
        "# obter máscaras com base nas bounding boxes\n",
        "transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, imagem_source.shape[:2]).to(\"cuda\")\n",
        "\n",
        "masks, _, _ = sam_predictor.predict_torch(\n",
        "            point_coords = None,\n",
        "            point_labels = None,\n",
        "            boxes = transformed_boxes,\n",
        "            multimask_output = False,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxBVtahZbu7W"
      },
      "outputs": [],
      "source": [
        "# Obter apenas as máscaras (preto e branco)\n",
        "def get_just_mask(mask):\n",
        "\n",
        "    color = np.array([255/255, 255/255, 255/255, 1]) # cor da máscara -> branca\n",
        "\n",
        "    tensor = torch.Tensor.cpu(mask)\n",
        "\n",
        "    h, w = mask.shape[-2:]\n",
        "\n",
        "    mask_image = tensor.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "\n",
        "    just_mask = Image.fromarray((mask_image.cpu().numpy() * 255).astype(np.uint8)).convert(\"L\")\n",
        "\n",
        "    return just_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU0cwIF6zd39"
      },
      "source": [
        "## **Criar uma máscara com todas as máscaras**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiAR46TfznMz"
      },
      "outputs": [],
      "source": [
        "mascaras = []\n",
        "mascara_resultados = np.zeros([imagem_source.shape[0], imagem_source.shape[1]], dtype=np.uint8) # gerar a máscara\n",
        "\n",
        "for item in masks:\n",
        "\n",
        "  temp = get_just_mask(item)\n",
        "  temp = np.array((temp))\n",
        "\n",
        "  mascaras.append(temp)\n",
        "\n",
        "# adicionar máscara geradas pelo SAM à máscara\n",
        "for i in range(0, len(mascaras)):\n",
        "\n",
        "  if boxes_xyxy[i][2].detach().numpy() - boxes_xyxy[i][0].detach().numpy() < 100:\n",
        "\n",
        "    mascara_resultados = cv2.add(mascara_resultados, mascaras[i])\n",
        "\n",
        "\n",
        "cv2_imshow(mascara_resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQBXQZ0P3EnD"
      },
      "source": [
        "### **Obter os contornos presentes na máscara**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adxkmhV9zzUz"
      },
      "outputs": [],
      "source": [
        "contornos, _ = cv2.findContours(mascara_resultados.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # obter os contrornos da imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63V-OaFZ3MQ3"
      },
      "source": [
        "## **Ordenar os contornos da esquerda para a direita**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRq2dk33RIr"
      },
      "outputs": [],
      "source": [
        "(contornos, _) = contours.sort_contours(contornos, method = \"left-to-right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQPAOmo23Wt8"
      },
      "source": [
        "## **Extrair contornos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE2IYN1q3aRr"
      },
      "outputs": [],
      "source": [
        "ep = 3 # padding\n",
        "\n",
        "crop_num = 0\n",
        "\n",
        "for contorno in contornos:\n",
        "\n",
        "  x, y, w, h = cv2.boundingRect(contorno) # obter a bounding box do contorno\n",
        "\n",
        "  if w < 60: # se a largura for menor do que 60, recortar o contorno\n",
        "\n",
        "    crop = mascara_resultados[y - ep : y + h + ep, x - ep : x + w + ep] # recortar contorno\n",
        "\n",
        "    resized_crop = cv2.resize(crop, (20, 20)) # redimensionar a imagem recortada\n",
        "\n",
        "\n",
        "    # guardar a imagem recortada\n",
        "\n",
        "    caminho = \"/content/\" # caminho onde serão guardadas as imagens\n",
        "\n",
        "    cv2.imwrite(os.path.join(caminho, f'crop{crop_num}.png'), resized_crop)\n",
        "\n",
        "    crop_num = crop_num + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QoHkwbJ30Gm"
      },
      "source": [
        "# **Classificação dos caracteres**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CSeaLh432g7"
      },
      "source": [
        "## **Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiSOdi3S30pL"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_wNuDb136Cr"
      },
      "source": [
        "## **Carregar o modelo de classificação**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPKcNTDW38ls"
      },
      "outputs": [],
      "source": [
        "input_shape = (20, 20, 3) # input que o modelo aceita\n",
        "num_classes = 34 # número de classes\n",
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E',\n",
        "              'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
        "              'U', 'V', 'W', 'X', 'Y', 'Z'] # nomes das classes -> não existe classe para a letra \"O\" e a letra \"I\"\n",
        "\n",
        "modelo = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(32, input_shape =input_shape),\n",
        "        layers.Dense(64, activation = 'relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(num_classes, activation = 'softmax'),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNV63MYd3967"
      },
      "outputs": [],
      "source": [
        "modelo.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUrecq0Q3_tc"
      },
      "source": [
        "## **Carregar pesos pré-treinados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FEig5YS4BAK"
      },
      "outputs": [],
      "source": [
        "caminho_pesos = \"/content/best_weights.h5\"\n",
        "modelo.load_weights(caminho_pesos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VySUJT9s4DGc"
      },
      "source": [
        "## **Classificar os caracteres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeK4eK7D4Erk"
      },
      "outputs": [],
      "source": [
        "imagem = cv2.imread('/content/crop0.png')\n",
        "\n",
        "cv2_imshow(imagem)\n",
        "\n",
        "imagem = np.expand_dims(imagem, axis = 0) # para garantir que as dimensões são as corretas\n",
        "\n",
        "previsao = modelo.predict(imagem) # classificação por parte do modelo\n",
        "\n",
        "classe = classes[np.argmax(previsao)] # classe prevista\n",
        "\n",
        "print(\"Classe previsa:\", classe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9EwHUxw4Gpt"
      },
      "source": [
        "# **Guardar resultados**\n",
        "Exemplo de como guardar texto num ficheiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX3rsTWj4GN8"
      },
      "outputs": [],
      "source": [
        "caminho_ficheiro_resultados = \"/content/resultados.txt\" # caminho onde será guardado o ficheiro\n",
        "\n",
        "resultados_f = open(caminho_ficheiro_resultados, \"a\") # gera o ficheiro caso não exista\n",
        "\n",
        "# adicionar resultado ao ficheiro dos resultados\n",
        "resultados_f.write(\"22XV69\" + '\\n') # \\n adiciona um parágrafo"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
